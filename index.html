<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">HandyLabels: Real-Time Annotation Tool Using Hand Gesture Recognition</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Sachin Kumar Singh</a><sup></sup>,</span>
                <span class="author-block">
                  <a href="https://brian-moser.github.io/" target="_blank">Brian B. Moser</a><sup></sup>,</span>
                  <span class="author-block">
                    <a href="https://sites.google.com/view/ko-watanabe/home" target="_blank">Ko Watanabe</a><sup></sup>,</span>
                    <span class="author-block">
                      <a href="https://agd.cs.uni-kl.de/" target="_blank">Andreas Dengel</a><sup></sup></span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">German Research Center for Artificial Intelligence (DFKI), Germany<br>RPTU Kaiserslautern-Landau, Germany</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/2.png" alt="HandyLabels Annotation Comparison" style="width:100%; height:auto;">
      <h2 class="subtitle has-text-centered">
        A comparison between a traditional label annotation tool (left) and our HandyLabels system (right). The traditional method requires manual inputs, such as mouse interactions, to label data, making it slow, inefficient, and lacking in real-time capabilities. In contrast, HandyLabels leverages real-time gesture-based annotations, significantly enhancing speed, robustness, and user experience. By enabling intuitive hand gestures for on-the-fly annotation, HandyLabels provides a more efficient and seamless approach to labeling, particularly suited for real-time applications.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The success of machine learning is deeply linked to the availability of high-quality training data, yet retrieving and manually
labeling new data remains a time-consuming and error-prone process. Traditional annotation tools like LabelStudio often require
post-processing, where users label data after recording. This cumbersome process leads to inefficiencies, particularly with large
datasets. In this work, we introduce HandyLabels, a real-time annotation tool that leverages hand gesture recognition to map hand
signs to labels during live recordings. The application allows users to customize gesture mappings through a web-based interface,
enabling real-time annotations. To validate the usability of HandyLabels, a user study was conducted with over 50 participants.
The results suggest that HandyLabels is preferred by the majority of participants compared to traditional annotation tools. To
ensure the robustness of HandyLabels, we evaluated several hand gesture recognition models on a custom dataset, with and without
skeleton-based pre-processing. The models were evaluated under challenging conditions (various backgrounds, distances, and devices)
to stress-test their robustness, with the goal of selecting the most reliable backbone for HandyLabels. Our experiments revealed that
models incorporating skeletal data, particularly the transformer-based ViT model (the backbone of HandyLabels), exhibited the highest
robustness.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h1 class="title has-text-centered">HandyLabels Application</h1>
      <img src="static/images/Diagram.png" alt="HandyLabels Annotation Comparison" style="width:100%; height:auto;">
      <h2 class="subtitle has-text-centered">
        This diagram illustrates the complete workflow of the HandyLabels application. (1) The process begins with the landing page
(Screen 1), where users can set custom labels for hand gestures. (2) Once users proceed to customize their labels, they are presented
with an interface to define unique gestures such as "happy" or "sad". (3) After labels are set, users can start the real-time gesture
recognition process, where gestures performed on Screen 1 are annotated as the video plays on Screen 2. (4) The workflow concludes
with a comprehensive overview of the recorded data, including a gesture data table and a distribution chart, allowing users to visualize
and export their results.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->


<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title">Data Collection</h2>
    <p>
      To evaluate the robustness and effectiveness of HandyLabels, a comprehensive dataset was collected under various conditions. 
      The data collection involved 19 participants who performed predefined hand gestures such as "Fist", "Peace", and "Thumbs Up" in different environments. 
      Data was collected using three distinct devices (iPhone 14 Pro Max, Sony X1 Camera, and MacBook Air) to simulate real-world scenarios. 
      The dataset includes gestures recorded from different distances (1 meter, 2 meters, and 3 meters) and against different backgrounds, 
      ensuring the system could handle environmental variations effectively.
    </p>
    <p>
      The collected dataset was further processed using skeleton-based preprocessing with MediaPipe, extracting 21 hand-knuckle landmarks to enhance gesture recognition accuracy.
    </p>
  </div>
</section>



<!-- User Study Section -->
<section class="hero is-light">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h1 class="title has-text-centered">User Study Overview</h1><br><br>
      <h2 class="subtitle has-text-centered">
        Detailed analysis of user preferences and setup effort comparison between HandyLabels and Label Studio.
      </h2>
      <p>
        To assess the usability and effectiveness of HandyLabels, we conducted a user study with over 50 participants. 
        The study compared HandyLabels with traditional annotation tools like LabelStudio, evaluating criteria such as ease of setup, 
        intuitiveness, and overall preference for labeling tasks.
      </p><br>

      <!-- Pie Charts: User Preferences -->
      <img src="static/images/pie_charts_handylables_bold_with_whitespace-1.png" alt="User Preferences for HandyLabels vs Label Studio" style="width:100%; height:auto;">
      <h2 class="subtitle has-text-centered">
        User preferences for HandyLabels compared to Label Studio. The first pie chart illustrates that the vast majority of users
        found HandyLabels more intuitive than Label Studio, with only a small percentage favoring Label Studio. The second chart reflects
        user preferences for data annotation, with 88.9% of participants indicating they would rather use HandyLabels for annotation tasks.
        The third chart shows that the majority would recommend HandyLabels, highlighting a strong overall preference for HandyLabels.
      </h2>

      <!-- Bar Charts: Setup Effort -->
      <img src="static/images/bar_chart_effort_annotation_tool_bold_subtitles-1.png" alt="Setup Effort Comparison for HandyLabels and Label Studio" style="width:100%; height:auto;">
      <h2 class="subtitle has-text-centered">
        Comparison of user ratings for setup effort between HandyLabels and Label Studio. The left bar chart shows that most
        participants found Label Studio more challenging to setup, with the majority giving it a difficulty rating of 4 or 5 (on a scale of 1
        to 5, where 5 is the hardest). In contrast, the right bar chart demonstrates that HandyLabels is much easier to setup, with most
        participants rating the effort as 1 or 2, indicating its user-friendly setup process.
      </h2>
    </div>
  </div>
</section>
<!-- End User Study Section -->


<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h1 class="title has-text-centered">Robustness Check</h1><br><br>
      <img src="static/images/Background.png" alt="HandyLabels Annotation Comparison" style="width:100%; height:auto;">
      <h2 class="subtitle has-text-centered">
        The first row shows the “peace” hand gesture against a green screen, followed by the backgrounds alone in the second row.
The third row combines the gesture with different backgrounds, while the fourth row applies skeleton-based pre-processing, mapping
hand landmarks to improve gesture recognition across varied environments.
      </h2>
    </div>
  </div>
</section> -->










<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>it 
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
